{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linkedin data\n",
    "linkedin_IS_appended = pd.read_csv('../extract_linkedIn_skills/cleaned_data/extracted/title_skill/appended_skill_IS_cleaned_03-10-2023_14-53-44.csv')\n",
    "linkedin_SE_appended = pd.read_csv('../extract_linkedIn_skills/cleaned_data/extracted/title_skill/appended_skill_SE_cleaned_03-10-2023_14-53-53.csv')\n",
    "\n",
    "# SIT modules\n",
    "ictIS_modules = pd.read_csv('../sit_crawler/data/ICT(IS)_Module_Description_Skills.csv')\n",
    "ictSE_modules = pd.read_csv('../sit_crawler/data/ICT(SE)_Module_Description_Skills.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mid-Senior level    311\n",
      "Entry level         127\n",
      "Associate            73\n",
      "Executive            20\n",
      "Internship            7\n",
      "Director              3\n",
      "Name: Seniority, dtype: int64\n",
      "\n",
      "Mid-Senior level    925\n",
      "Entry level         479\n",
      "Associate           149\n",
      "Executive            41\n",
      "Director             40\n",
      "Internship           24\n",
      "Name: Seniority, dtype: int64\n",
      "['Unnamed: 0', 'Job Title', 'Job URN', 'Company Name', 'Location', 'Applicants', 'Seniority', 'Employment type', 'Job function', 'Industries', 'Job description', 'Posted on', 'Skills', 'Extracted Skills']\n",
      "['Unnamed: 0', 'Job Title', 'Job URN', 'Company Name', 'Location', 'Applicants', 'Seniority', 'Employment type', 'Job function', 'Industries', 'Job description', 'Posted on', 'Skills', 'Extracted Skills']\n"
     ]
    }
   ],
   "source": [
    "# check datasets\n",
    "\n",
    "# remove NA values in seniority\n",
    "linkedin_IS_appended = linkedin_IS_appended.dropna()\n",
    "linkedin_SE_appended = linkedin_SE_appended.dropna()\n",
    "\n",
    "# check: Seniority\n",
    "print(linkedin_IS_appended['Seniority'].value_counts())\n",
    "print()\n",
    "print(linkedin_SE_appended['Seniority'].value_counts())\n",
    "\n",
    "print(linkedin_IS_appended.columns.values.tolist())\n",
    "print(linkedin_SE_appended.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/xinhui/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# for lemmatization\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_word(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import spacy\n",
    "\n",
    "# Load the trained model from the file\n",
    "loaded_model = joblib.load('./models/skill_classifier_model.pkl')\n",
    "classifier = joblib.load('./models/classifier_model_3.pkl')\n",
    "\n",
    "# Load spaCy model for tokenization (not needed for new model)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction model (OLD METHOD)\n",
    "def predict_skill(skill):\n",
    "    skill = skill.lower().strip()\n",
    "    skill = lemmatize_word(skill)\n",
    "    new_skill = skill\n",
    "    new_skill_vector = nlp(new_skill).vector\n",
    "\n",
    "    # Use the loaded model for prediction\n",
    "    prediction = loaded_model.predict([new_skill_vector])\n",
    "\n",
    "    # Interpret the prediction (CHECK)\n",
    "    # if skill.lower() == \"advocacy\":\n",
    "    # if prediction[0] != 1:\n",
    "    #     print(f\"\\n\\n{new_skill} is a soft skill.\")\n",
    "    # else:\n",
    "    #     print(f\"\\n\\n{new_skill} is a hard skill.\")\n",
    "\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the vectorizer\n",
    "vectorizer = joblib.load('./models/vectorizer_3.pkl')\n",
    "\n",
    "# Deploy the model\n",
    "def predict_skill_2(skill):\n",
    "    skill_vector = vectorizer.transform([skill])\n",
    "    prediction = classifier.predict_proba(skill_vector)\n",
    "\n",
    "    if prediction[0][1] > 0.5:\n",
    "        return \"hard skill\"\n",
    "    else:\n",
    "        return \"soft skill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_skill_linkedin(df):\n",
    "    overall_hard_skill = {}\n",
    "    overall_soft_skill = {}\n",
    "    for index, row in df.iterrows():\n",
    "        curr_hSkill = []\n",
    "        curr_sSkill = []\n",
    "        # print(row['Extracted Skills'])\n",
    "        skills_list = row[\"Extracted Skills\"].split(\",\")\n",
    "\n",
    "        for skill in skills_list:\n",
    "            predict_skill_type = predict_skill(skill) # -> OLD METHOD\n",
    "            # predict_skill_type = predict_skill_2(skill)\n",
    "            if predict_skill_type == 1:\n",
    "                curr_hSkill.append(skill)\n",
    "                overall_hard_skill[skill] = (\n",
    "                    overall_hard_skill[skill] + 1 if skill in overall_hard_skill else 1\n",
    "                )\n",
    "            else:  # predict_skill_type = 0\n",
    "                curr_sSkill.append(skill)\n",
    "                overall_soft_skill[skill] = (\n",
    "                    overall_soft_skill[skill] + 1 if skill in overall_soft_skill else 1\n",
    "                )\n",
    "\n",
    "        # hard_skill.append(','.join(curr_hSkill))\n",
    "        df.at[index, \"Hard Skill\"] = \",\".join(curr_hSkill)\n",
    "        df.at[index, \"Soft Skill\"] = \",\".join(curr_sSkill)\n",
    "\n",
    "    return [df, overall_hard_skill, overall_soft_skill]\n",
    "\n",
    "\n",
    "(\n",
    "    categorised_IS,\n",
    "    overall_hard_skill_IS,\n",
    "    overall_soft_skill_IS,\n",
    ") = categorize_skill_linkedin(linkedin_IS_appended)\n",
    "(\n",
    "    categorised_SE,\n",
    "    overall_hard_skill_SE,\n",
    "    overall_soft_skill_SE,\n",
    ") = categorize_skill_linkedin(linkedin_SE_appended)\n",
    "\n",
    "categorised_IS.to_csv(\"./data/categorised_IS\", encoding=\"utf-8\")\n",
    "categorised_SE.to_csv(\"./data/categorised_SE\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cyber Security', 313),\n",
       " ('Computer Science', 242),\n",
       " ('Operations', 159),\n",
       " ('Innovation', 151),\n",
       " ('Vulnerability', 146),\n",
       " ('Certified Information Systems Security Professional', 136),\n",
       " ('Problem Solving', 128),\n",
       " ('Firewall', 123),\n",
       " ('Auditing', 121),\n",
       " ('Information Technology', 113),\n",
       " ('Network Security', 99),\n",
       " ('Incident Response', 97),\n",
       " ('Cyber Threat Intelligence', 89),\n",
       " ('Troubleshooting (Problem Solving)', 88),\n",
       " ('Automation', 86),\n",
       " ('Python (Programming Language)', 84),\n",
       " ('Security Policies', 83),\n",
       " ('Risk Analysis', 82),\n",
       " ('Project Management', 81),\n",
       " ('Governance', 78),\n",
       " ('Security Information And Event Management (SIEM)', 78),\n",
       " ('Risk Management', 77),\n",
       " ('Leadership', 74),\n",
       " ('Agile Methodology', 71),\n",
       " ('Penetration Testing', 69),\n",
       " ('Research', 68),\n",
       " ('Amazon Web Services', 66),\n",
       " ('Certified Information System Auditor (CISA)', 64),\n",
       " ('Vulnerability Assessments', 64),\n",
       " ('Writing', 64),\n",
       " ('Artificial Intelligence', 62),\n",
       " ('Planning', 62),\n",
       " ('Scripting', 60),\n",
       " ('Presentations', 59),\n",
       " ('Interpersonal Communications', 59),\n",
       " ('Certified Information Security Manager', 59),\n",
       " ('Microsoft Azure', 56),\n",
       " ('Consulting', 56),\n",
       " ('Digital Transformation', 55),\n",
       " ('Network Infrastructure', 55),\n",
       " ('Cloud Security', 52),\n",
       " ('Virtual Private Networks (VPN)', 51),\n",
       " ('Customer Service', 51),\n",
       " ('Network Routing', 50),\n",
       " ('Linux', 50),\n",
       " ('Mitigation', 50),\n",
       " ('Operating Systems', 49),\n",
       " ('Data Analysis', 49),\n",
       " ('Application Development', 48),\n",
       " ('GIAC Certifications', 48)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# Create a Counter object from the dictionary\n",
    "counter = collections.Counter(overall_hard_skill_IS)\n",
    "counter.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
